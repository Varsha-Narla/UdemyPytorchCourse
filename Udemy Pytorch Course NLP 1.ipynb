{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f6ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84406640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7406a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\DELL\\OneDrive\\Desktop\\PYTORCH_NOTEBOOKS\\Data\\shakespeare.txt', 'r', encoding='utf8') as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1da441a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91b81a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bud buriest thy content,\n",
      "  And tender churl mak'st waste in niggarding:\n",
      "    Pity the world, or else this glutton be,\n",
      "    To eat the world's due, by the grave and thee.\n",
      "\n",
      "\n",
      "                     2\n",
      "  When forty winters shall besiege thy brow,\n",
      "  And dig deep trenches in thy beauty's field,\n",
      "  Thy youth's proud livery so gazed on now,\n",
      "  Will be a tattered weed of small worth held:  \n",
      "  Then being asked, where all thy beauty lies,\n",
      "  Where all the treasure of thy lusty days;\n",
      "  To say within thine own deep su\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15caffd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5445609"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a2a50db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters=set(text)\n",
    "len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b22ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes number value and returns the corresponding char \n",
    "decoder=dict(enumerate(all_characters))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4549d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '-',\n",
       " 1: 'D',\n",
       " 2: 'b',\n",
       " 3: ')',\n",
       " 4: 'B',\n",
       " 5: 'e',\n",
       " 6: '3',\n",
       " 7: '5',\n",
       " 8: 'Z',\n",
       " 9: '.',\n",
       " 10: 'g',\n",
       " 11: '7',\n",
       " 12: 'Q',\n",
       " 13: 'n',\n",
       " 14: '?',\n",
       " 15: 'k',\n",
       " 16: ' ',\n",
       " 17: 'I',\n",
       " 18: 'T',\n",
       " 19: 'i',\n",
       " 20: 'x',\n",
       " 21: 'N',\n",
       " 22: '9',\n",
       " 23: '|',\n",
       " 24: 't',\n",
       " 25: 'q',\n",
       " 26: '[',\n",
       " 27: 'U',\n",
       " 28: '\\n',\n",
       " 29: 'J',\n",
       " 30: '1',\n",
       " 31: 'l',\n",
       " 32: '8',\n",
       " 33: 'r',\n",
       " 34: '4',\n",
       " 35: 'L',\n",
       " 36: 'K',\n",
       " 37: 'h',\n",
       " 38: 'A',\n",
       " 39: 'z',\n",
       " 40: 'C',\n",
       " 41: ']',\n",
       " 42: '!',\n",
       " 43: 'c',\n",
       " 44: '`',\n",
       " 45: '2',\n",
       " 46: '&',\n",
       " 47: 'P',\n",
       " 48: '\"',\n",
       " 49: 'v',\n",
       " 50: '_',\n",
       " 51: 'Y',\n",
       " 52: 'o',\n",
       " 53: 'R',\n",
       " 54: 'V',\n",
       " 55: 'p',\n",
       " 56: 'F',\n",
       " 57: ':',\n",
       " 58: 'G',\n",
       " 59: '>',\n",
       " 60: '0',\n",
       " 61: 'H',\n",
       " 62: 'f',\n",
       " 63: 'W',\n",
       " 64: 'S',\n",
       " 65: 'm',\n",
       " 66: 'O',\n",
       " 67: 'a',\n",
       " 68: '<',\n",
       " 69: ',',\n",
       " 70: \"'\",\n",
       " 71: 'X',\n",
       " 72: '}',\n",
       " 73: ';',\n",
       " 74: 'y',\n",
       " 75: 'M',\n",
       " 76: 'j',\n",
       " 77: 'u',\n",
       " 78: 'd',\n",
       " 79: '(',\n",
       " 80: 'E',\n",
       " 81: 's',\n",
       " 82: 'w',\n",
       " 83: '6'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "076d572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#letter -> number\n",
    "encoder={char: ind for ind, char in decoder.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1038311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-': 0,\n",
       " 'D': 1,\n",
       " 'b': 2,\n",
       " ')': 3,\n",
       " 'B': 4,\n",
       " 'e': 5,\n",
       " '3': 6,\n",
       " '5': 7,\n",
       " 'Z': 8,\n",
       " '.': 9,\n",
       " 'g': 10,\n",
       " '7': 11,\n",
       " 'Q': 12,\n",
       " 'n': 13,\n",
       " '?': 14,\n",
       " 'k': 15,\n",
       " ' ': 16,\n",
       " 'I': 17,\n",
       " 'T': 18,\n",
       " 'i': 19,\n",
       " 'x': 20,\n",
       " 'N': 21,\n",
       " '9': 22,\n",
       " '|': 23,\n",
       " 't': 24,\n",
       " 'q': 25,\n",
       " '[': 26,\n",
       " 'U': 27,\n",
       " '\\n': 28,\n",
       " 'J': 29,\n",
       " '1': 30,\n",
       " 'l': 31,\n",
       " '8': 32,\n",
       " 'r': 33,\n",
       " '4': 34,\n",
       " 'L': 35,\n",
       " 'K': 36,\n",
       " 'h': 37,\n",
       " 'A': 38,\n",
       " 'z': 39,\n",
       " 'C': 40,\n",
       " ']': 41,\n",
       " '!': 42,\n",
       " 'c': 43,\n",
       " '`': 44,\n",
       " '2': 45,\n",
       " '&': 46,\n",
       " 'P': 47,\n",
       " '\"': 48,\n",
       " 'v': 49,\n",
       " '_': 50,\n",
       " 'Y': 51,\n",
       " 'o': 52,\n",
       " 'R': 53,\n",
       " 'V': 54,\n",
       " 'p': 55,\n",
       " 'F': 56,\n",
       " ':': 57,\n",
       " 'G': 58,\n",
       " '>': 59,\n",
       " '0': 60,\n",
       " 'H': 61,\n",
       " 'f': 62,\n",
       " 'W': 63,\n",
       " 'S': 64,\n",
       " 'm': 65,\n",
       " 'O': 66,\n",
       " 'a': 67,\n",
       " '<': 68,\n",
       " ',': 69,\n",
       " \"'\": 70,\n",
       " 'X': 71,\n",
       " '}': 72,\n",
       " ';': 73,\n",
       " 'y': 74,\n",
       " 'M': 75,\n",
       " 'j': 76,\n",
       " 'u': 77,\n",
       " 'd': 78,\n",
       " '(': 79,\n",
       " 'E': 80,\n",
       " 's': 81,\n",
       " 'w': 82,\n",
       " '6': 83}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "074c72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text=np.array([encoder[char] for char in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f57b656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       16, 16, 16, 16, 16, 30, 28, 16, 16, 56, 33, 52, 65, 16, 62, 67, 19,\n",
       "       33,  5, 81, 24, 16, 43, 33,  5, 67, 24, 77, 33,  5, 81, 16, 82,  5,\n",
       "       16, 78,  5, 81, 19, 33,  5, 16, 19, 13, 43, 33,  5, 67, 81,  5, 69,\n",
       "       28, 16, 16, 18, 37, 67, 24, 16, 24, 37,  5, 33,  5,  2, 74, 16,  2,\n",
       "        5, 67, 77, 24, 74, 70, 81, 16, 33, 52, 81,  5, 16, 65, 19, 10, 37,\n",
       "       24, 16, 13,  5, 49,  5, 33, 16, 78, 19,  5, 69, 28, 16, 16,  4, 77,\n",
       "       24, 16, 67, 81, 16, 24, 37,  5, 16, 33, 19, 55,  5, 33, 16, 81, 37,\n",
       "       52, 77, 31, 78, 16,  2, 74, 16, 24, 19, 65,  5, 16, 78,  5, 43,  5,\n",
       "       67, 81,  5, 69, 28, 16, 16, 61, 19, 81, 16, 24,  5, 13, 78,  5, 33,\n",
       "       16, 37,  5, 19, 33, 16, 65, 19, 10, 37, 24, 16,  2,  5, 67, 33, 16,\n",
       "       37, 19, 81, 16, 65,  5, 65, 52, 33, 74, 57, 28, 16, 16,  4, 77, 24,\n",
       "       16, 24, 37, 52, 77, 16, 43, 52, 13, 24, 33, 67, 43, 24,  5, 78, 16,\n",
       "       24, 52, 16, 24, 37, 19, 13,  5, 16, 52, 82, 13, 16,  2, 33, 19, 10,\n",
       "       37, 24, 16,  5, 74,  5, 81, 69, 28, 16, 16, 56,  5,  5, 78, 70, 81,\n",
       "       24, 16, 24, 37, 74, 16, 31, 19, 10, 37, 24, 70, 81, 16, 62, 31, 67,\n",
       "       65,  5, 16, 82, 19, 24, 37, 16, 81,  5, 31, 62,  0, 81, 77,  2, 81,\n",
       "       24, 67, 13, 24, 19, 67, 31, 16, 62, 77,  5, 31, 69, 28, 16, 16, 75,\n",
       "       67, 15, 19, 13, 10, 16, 67, 16, 62, 67, 65, 19, 13,  5, 16, 82, 37,\n",
       "        5, 33,  5, 16, 67,  2, 77, 13, 78, 67, 13, 43,  5, 16, 31, 19,  5,\n",
       "       81, 69, 28, 16, 16, 18, 37, 74, 16, 81,  5, 31, 62, 16, 24, 37, 74,\n",
       "       16, 62, 52,  5, 69, 16, 24, 52, 16, 24, 37, 74, 16, 81, 82,  5,  5,\n",
       "       24, 16, 81,  5, 31, 62, 16, 24, 52, 52, 16, 43, 33, 77,  5, 31, 57,\n",
       "       28, 16, 16, 18, 37, 52, 77, 16, 24, 37, 67, 24, 16, 67, 33, 24, 16,\n",
       "       13, 52, 82, 16, 24, 37,  5, 16, 82, 52, 33, 31, 78, 70, 81, 16, 62,\n",
       "       33,  5, 81, 37, 16, 52, 33, 13, 67, 65,  5, 13, 24, 69, 28, 16, 16,\n",
       "       38, 13, 78, 16, 52, 13, 31, 74, 16, 37,  5, 33, 67, 31, 78, 16, 24,\n",
       "       52, 16, 24, 37,  5, 16, 10, 67, 77, 78, 74, 16, 81, 55, 33, 19, 13,\n",
       "       10, 69, 28, 16, 16, 63, 19, 24, 37, 19, 13, 16, 24, 37, 19, 13,  5,\n",
       "       16, 52, 82, 13, 16,  2, 77])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfc263b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder[68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9e3651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot_encoder(encoded_text, num_uni_chars):\n",
    "    # encoded_text ---> batch of encoded text \n",
    "    # num_uni_chars ---> number of unique characters\n",
    "    \n",
    "    # Initialize the one-hot encoding array with zeros\n",
    "    one_hot = np.zeros((encoded_text.size, num_uni_chars), dtype=np.float32)\n",
    "    \n",
    "    # Set specific indices to 1.0 for one-hot encoding\n",
    "    one_hot[np.arange(encoded_text.size), encoded_text.flatten()] = 1.0\n",
    "    \n",
    "    # Reshape to match the original batch dimensions with one-hot encoding depth\n",
    "    one_hot = one_hot.reshape((*encoded_text.shape, num_uni_chars))\n",
    "    \n",
    "    return one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ca4617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=np.array([1,2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41541043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a220acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder(arr,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f31c7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text=np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2b4023a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f66fab09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text.reshape(5,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "258b50f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(encoded_text, samp_per_batch=10, seq_len=50):\n",
    "    #x is the encoded text of seq_len \n",
    "    #y is the encoded shifted by 1 \n",
    "    \n",
    "    chars_per_batch=samp_per_batch*seq_len\n",
    "    num_batches_avail=int(len(encoded_text)/chars_per_batch)\n",
    "    encoded_text=encoded_text[:num_batches_avail*chars_per_batch]\n",
    "    \n",
    "    encoded_text=encoded_text.reshape((samp_per_batch,-1))\n",
    "    \n",
    "    for n in range(0, encoded_text.shape[1], seq_len):\n",
    "        x=encoded_text[:,n:n+seq_len]\n",
    "        \n",
    "        y=np.zeros_like(x)\n",
    "        \n",
    "        try:\n",
    "            y[:, :-1]=x[:,1:]\n",
    "            \n",
    "            y[:,-1]=encoded_text[:,n+seq_len]\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            y[:,:-1]=x[:,1:]\n",
    "            y[:,-1]=encoded_text[:,0]\n",
    "            \n",
    "        yield x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9aa8925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text=np.arange(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79e2e716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "beeb90c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator=generate_batches(sample_text, samp_per_batch=2, seq_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b48b7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=next(batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c34c541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [10, 11, 12, 13, 14]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "798e7887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [11, 12, 13, 14, 15]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y #the numbers below are one shifted to the right of x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "28d2ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, all_chars, num_hidden=256, num_layers=5, drop_prob=0.5, use_gpu=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.drop_prob=drop_prob\n",
    "        self.num_layers=num_layers\n",
    "        self.num_hidden=num_hidden\n",
    "        self.use_gpu=use_gpu\n",
    "        \n",
    "        self.all_chars=all_chars\n",
    "        self.decoder=dict(enumerate(all_chars))\n",
    "        self.encoder={char: ind for ind, char in self.decoder.items()}\n",
    "        \n",
    "        self.lstm=nn.LSTM(len(self.all_chars), num_hidden, num_layers, dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        self.dropout=nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.fc_linear=nn.Linear(num_hidden, len(self.all_chars))\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        lstm_output, hidden=self.lstm(x, hidden)\n",
    "        \n",
    "        drop_output=self.dropout(lstm_output)\n",
    "        \n",
    "        drop_output=drop_output.contiguous().view(-1, self.num_hidden)\n",
    "        \n",
    "        final_out=self.fc_linear(drop_output)\n",
    "        \n",
    "        return final_out, hidden\n",
    "    \n",
    "    def hidden_state(self, batch_size):\n",
    "        if self.use_gpu:\n",
    "            hidden=(torch.zeros(self.num_layers,batch_size, self.num_hidden).cuda(),\n",
    "                    torch.zeros(self.num_layers,batch_size, self.num_hidden).cuda())\n",
    "        else:\n",
    "            hidden=(torch.zeros(self.num_layers,batch_size, self.num_hidden),\n",
    "                    torch.zeros(self.num_layers,batch_size, self.num_hidden))\n",
    "            \n",
    "        return hidden\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8d215acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CharModel(all_chars=all_characters,\n",
    "               num_hidden=512,\n",
    "               num_layers=3,\n",
    "               drop_prob=0.5,\n",
    "               use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3830841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_param=[]\n",
    "\n",
    "for p in model.parameters():\n",
    "    total_param.append(int(p.numel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eb9fa564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[172032,\n",
       " 1048576,\n",
       " 2048,\n",
       " 2048,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2048,\n",
       " 2048,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2048,\n",
       " 2048,\n",
       " 43008,\n",
       " 84]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d68c9134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5470292"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(total_param) #size of the dataset approx which is a good thing, else model overfits/underfits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "12e26740",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "28897855",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "41e2ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind=int(len(encoded_text)*train_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eb92d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=encoded_text[:train_ind]\n",
    "val_data=encoded_text[train_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "86c9c96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544560"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "836012a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4901049"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5f8684e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1\n",
    "batch_size=100\n",
    "seq_len=100\n",
    "tracker=0\n",
    "num_chars=max(encoded_text)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "127cb241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3056\\2953598870.py:27: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), max_norm=5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0 Step: 75 VAL LOSS: 3.195875883102417\n",
      "EPOCH: 0 Step: 100 VAL LOSS: 3.1826040744781494\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model=model.cuda()\n",
    "    \n",
    "for i in range(epochs):\n",
    "    hidden=model.hidden_state(batch_size)\n",
    "    for x,y in generate_batches(train_data, batch_size, seq_len):\n",
    "        tracker+=1\n",
    "        x=one_hot_encoder(x, num_chars)\n",
    "        inputs=torch.from_numpy(x)\n",
    "        targets=torch.from_numpy(y)\n",
    "        \n",
    "        if model.use_gpu:\n",
    "            inputs=inputs.cuda()\n",
    "            targets=targets.cuda()\n",
    "            \n",
    "        hidden=tuple([state.data for state in hidden])\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        lstm_output, hidden=model.forward(inputs, hidden)\n",
    "        loss=criterion(lstm_output, targets.view(batch_size*seq_len).long())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm(model.parameters(), max_norm=5)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if tracker%25==0:\n",
    "            val_hidden=model.hidden_state(batch_size)\n",
    "            val_losses=[]\n",
    "            model.eval()\n",
    "            \n",
    "            for x,y in generate_batches(val_data,batch_size,seq_len):\n",
    "                x=one_hot_encoder(x, num_chars)\n",
    "                inputs=torch.from_numpy(x)\n",
    "                targets=torch.from_numpy(y)\n",
    "                \n",
    "                if model.use_gpu:\n",
    "                    inputs=inputs.cuda()\n",
    "                    targets=targets.cuda()\n",
    "                    \n",
    "                val_hidden=tuple([state.data for state in val_hidden])\n",
    "                \n",
    "                lstm_output,val_hidden=model.forward(inputs, val_hidden)\n",
    "                val_loss=criterion(lstm_output, targets.view(batch_size*seq_len).long())\n",
    "                \n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            model.train()\n",
    "            print(f\"EPOCH: {i} Step: {tracker} VAL LOSS: {val_loss.item()}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "83d31211",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='hidden512_layers3_shakes.net'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "57db1d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1fe0a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define one_hot_encoded function\n",
    "def one_hot_encoded(encoded_text, num_chars):\n",
    "    one_hot = np.zeros((encoded_text.size, num_chars))\n",
    "    one_hot[np.arange(encoded_text.size), encoded_text] = 1\n",
    "    return one_hot\n",
    "\n",
    "# Define predict_next_char function\n",
    "def predict_next_char(model, char, hidden=None, k=1):\n",
    "    # Encoding the character\n",
    "    encoded_text = model.encoder[char]\n",
    "    encoded_text = np.array([[encoded_text]])\n",
    "    \n",
    "    # One-hot encoding the encoded character\n",
    "    encoded_text = one_hot_encoded(encoded_text, len(model.all_chars))\n",
    "    inputs = torch.from_numpy(encoded_text).float().unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    # Passing the hidden state without gradients\n",
    "    hidden = tuple([state.data for state in hidden])\n",
    "    \n",
    "    # Getting LSTM output and new hidden state\n",
    "    lstm_out, hidden = model(inputs, hidden)\n",
    "    \n",
    "    # Calculating probabilities\n",
    "    probs = F.softmax(lstm_out, dim=1).data\n",
    "    probs, index_positions = probs.topk(k)\n",
    "    \n",
    "    # Converting to numpy for manipulation\n",
    "    index_positions = index_positions.numpy().squeeze()\n",
    "    probs = probs.numpy().flatten()\n",
    "    probs = probs / probs.sum()  # Normalize to get probabilities\n",
    "    \n",
    "    # Selecting a character based on probabilities\n",
    "    char = np.random.choice(index_positions, p=probs)\n",
    "    \n",
    "    # Return the predicted character and the hidden state\n",
    "    return model.decoder[char], hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "67849128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, size, seed='The', k=1):\n",
    "    model.cpu()\n",
    "    model.eval()\n",
    "    output_chars=[c for c in seed]\n",
    "    \n",
    "    hidden=model.hidden_state(1)\n",
    "    \n",
    "    for char in seed:\n",
    "        char, hidden=predict_next_char(model, char, hidden, k=k)\n",
    "        \n",
    "    output_chars.append(char)\n",
    "    \n",
    "    for i in range(size):\n",
    "        char,hidden=predict_next_char(model, output_chars[-1], hidden, k=k)\n",
    "        \n",
    "        output_chars.append(char)\n",
    "        \n",
    "    return ''.join(output_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ad0ab1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The e   e te   t  e e e  e e te  t  e   te  e   e      e e  t   e     t  e  ee    t  e   e         tee  te          e   e eete  e t e  t  t tett ee    t        e  ee      t  tee  e  ee  te  ee    e   et   e     ee ee      t eet tt ee     eteet   te  t    eet  ettte   tee      t e     ee tee e   e   t  ete  e   t   t ee         eeeete     e  tt    e e          e      ee   e t   e      tt e    eee   e    te     e  e e e e  e   ee   e    ee    e  t  e ee   t       t   e teee     eet  e          e et    tte  e     t  te ete      t          e et eee ee     t e          ee  t t     tt      ee    eet      et tte     t     t   ett  e    t  t       t t   ee    e     t t   e t   ee  t t    e  t t tt  e   t      t   t  te   e   et t    e e     e  e t ee teetee  t   t  te  t   e     t e eeeee        e  e e t te     e   e  e  e e     e t et e   ete  tee  t   t       e e ette  tet  ee tet eet  t ettt      e   tee e ete  ett teee ete     tt eet        ttt      e  tt   t et     e e ee e      e   ee e t    \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, 1000, seed='The ', k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7701387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
